{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing and pickling data for repeated use\n",
    "\n",
    "The DATADIR constant and CATEGORIES arrays are to be adjusted to point to the location of the training data and to subfolders that contain the training data of different classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "DATADIR = \"data/SIDS/images\"\n",
    "CATEGORIES = [\"ok_partA\", \"warn_partB\", \"alarm_partC\"]\n",
    "\n",
    "training_data = []\n",
    "\n",
    "IMG_SIZE = 100\n",
    "\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR, category)\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                training_data.append([new_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "create_training_data()\n",
    "print(len(training_data))\n",
    "\n",
    "\n",
    "random.shuffle(training_data)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for features,label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "    \n",
    "X = np.array(X).reshape(len(training_data), IMG_SIZE, IMG_SIZE, 1)\n",
    "y = np.array(y)\n",
    "\n",
    "import pickle\n",
    "\n",
    "pickle_out = open(\"X.pickle\",\"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y.pickle\",\"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation\n",
    "\n",
    "Different combinations of the desnse layer, kernel size and number of convulutional layers are tried out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "import tensorflow.keras.backend as K\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)\n",
    "\n",
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "\n",
    "X = X/255.0\n",
    "\n",
    "dense_layers =  [0]#[3, 4, 8]\n",
    "layer_sizes =  [32]#[32, 64, 128]\n",
    "conv_layers = [3]#[1, 2, 3]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "            print(NAME)\n",
    "\n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Conv2D(layer_size, (3, 3), input_shape=X.shape[1:]))\n",
    "            model.add(Activation('relu'))\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            for l in range(conv_layer-1):\n",
    "                model.add(Conv2D(layer_size, (3, 3)))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            model.add(Flatten())\n",
    "\n",
    "            for _ in range(dense_layer):\n",
    "                model.add(Dense(layer_size))\n",
    "                model.add(Activation('relu'))\n",
    "                \n",
    "            model.add(Dropout(0.5))\n",
    "            model.add(Dense(3))\n",
    "            model.add(Activation('sigmoid'))\n",
    "\n",
    "            tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "\n",
    "            model.compile(loss='sparse_categorical_crossentropy',\n",
    "                          optimizer='adam',\n",
    "                          metrics=['accuracy'],\n",
    "                          )\n",
    "\n",
    "            model.fit(X, y,\n",
    "                      batch_size=32,\n",
    "                      epochs=20,\n",
    "                      validation_split=0.1,\n",
    "                      callbacks=[tensorboard])\n",
    "            model.save(NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "camera = cv2.VideoCapture(1)\n",
    "for i in range(3):\n",
    "    return_value, image = camera.read()\n",
    "    cv2.imwrite('opencv'+str(i)+'.jpeg', image)\n",
    "del(camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the model\n",
    "Contiounuly takes in images off the webcam, applies the model, and if the baby is turning, leverages the AWS SNS to sent a notification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import boto3\n",
    "\n",
    "def imageName(imageNumber):\n",
    "    return 'opencv'+str(imageNumber)+'.jpeg'\n",
    "\n",
    "def takePictures(numberOfPictures):\n",
    "    camera = cv2.VideoCapture(1)\n",
    "    for i in range(numberOfPictures):\n",
    "        return_value, image = camera.read()\n",
    "        cv2.imwrite(imageName(i), image)\n",
    "    del(camera)\n",
    "    \n",
    "def prepare(filepath):\n",
    "    filedir='out/dir/'  # this filedirectory need to exist for the images to be written\n",
    "    IMG_SIZE = 100\n",
    "    img_array = cv2.imread(os.path.join(filedir,filepath), cv2.IMREAD_GRAYSCALE)\n",
    "    img_array = img_array/255\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "def findCategory(prediction_inner):\n",
    "    p=prediction_inner\n",
    "    a=np.argmax(p)\n",
    "    return a-1\n",
    "\n",
    "\n",
    "def alarmAlert():\n",
    "    print(\"*******************************************************\")\n",
    "    print(\"*******************************************************\")\n",
    "    #push notification initiated\n",
    "    client = boto3.client(\"sns\",aws_access_key_id=\"XXXXXXXXXXXXXXXXXXXXXX\",  # replace with the aws access key\n",
    "                          aws_secret_access_key=\"XXXXXXXXXXXXXXXXXXXX\",   # replace with the aws secret access key\n",
    "                          region_name=\"us-east-2\")\n",
    "    client.publish(TopicArn=\"arn:aws:sns:us-east-2:470609516118:SidsAlert\", # replace with the aws SNS topic Arn\n",
    "                   Subject=\"SIDS Alert\",\n",
    "                   Message=\"Baby is turning\")\n",
    "\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        model = tf.keras.models.load_model(\"2-conv-32-nodes-0-dense-1606724863\")\n",
    "        frame1 = 1\n",
    "        frame2 = 1\n",
    "        frame3 = 1\n",
    "        takePictures(3)\n",
    "        prediction1 = model.predict([prepare(imageName(0))])\n",
    "        #print(prediction1)\n",
    "        prediction2 = model.predict([prepare(imageName(1))])\n",
    "        #print(prediction2)\n",
    "        prediction3 = model.predict([prepare(imageName(2))])\n",
    "        #print(prediction3)\n",
    "        frame1=findCategory(prediction1[0])\n",
    "        #print(frame1)\n",
    "        frame2=findCategory(prediction2[0])\n",
    "        #print(frame2)\n",
    "        frame3=findCategory(prediction3[0])\n",
    "        #print(frame3)\n",
    "        if(frame1==1) and (frame2==1) and (frame3==1):\n",
    "            print(\"OK\")\n",
    "        elif(frame1==0) and (frame2==0) and (frame3==0):\n",
    "            alarmAlert()\n",
    "            os.system('say \"the baby has turned over\"')\n",
    "        elif(frame1==2) and (frame2==2) and (frame3==2):\n",
    "            print(\"WARN\")\n",
    "            alarmAlert()\n",
    "            os.system('say \"the baby is turning\"')\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Images \n",
    "Gnerates images (by Rotating, panning, shearing, zooming, horizontally flipping) existing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.05,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "DATADIR = \"data/images/alarm_partC\"\n",
    "OUT_DATADIR = \"data/genImage/alarm_partC\"\n",
    "LABEL = \"alarm\"\n",
    "# Alarm has 130 raw images from videos\n",
    "for img_file in tqdm(os.listdir(DATADIR)):\n",
    "    img = load_img(os.path.join(DATADIR,img_file))  # this is a PIL image\n",
    "    x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "    x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "    \n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1,save_to_dir=OUT_DATADIR, save_prefix=LABEL, save_format='jpeg'):\n",
    "        i +=1\n",
    "        if i > 3: \n",
    "            break\n",
    "\n",
    "DATADIR = \"data/images/ok_partA\"\n",
    "OUT_DATADIR = \"data/genImage/ok_partA\"\n",
    "LABEL = \"ok\"\n",
    "# Alarm has 166 raw images from videos\n",
    "for img_file in tqdm(os.listdir(DATADIR)):\n",
    "    img = load_img(os.path.join(DATADIR,img_file))  # this is a PIL image\n",
    "    x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "    x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "    \n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1,save_to_dir=OUT_DATADIR, save_prefix=LABEL, save_format='jpeg'):\n",
    "        i +=1\n",
    "        if i > 3: \n",
    "            break\n",
    "\n",
    "            \n",
    "DATADIR = \"data/images/warn_partB\"\n",
    "OUT_DATADIR = \"data/genImage/warn_partB\"\n",
    "LABEL = \"warn\"\n",
    "# Alarm has 166 raw images from videos\n",
    "for img_file in tqdm(os.listdir(DATADIR)):\n",
    "    img = load_img(os.path.join(DATADIR,img_file))  # this is a PIL image\n",
    "    x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "    x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "    \n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1,save_to_dir=OUT_DATADIR, save_prefix=LABEL, save_format='jpeg'):\n",
    "        i +=1\n",
    "        if i > 3: \n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
